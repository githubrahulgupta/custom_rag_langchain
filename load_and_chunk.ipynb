{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config - INFO - Current Working Directory: c:\\Users\\Rahul Gupta\\Documents\\RG\\GenAI\\0.self_explore\n",
      "config - INFO - Folder separator used w.r.t OS: \\\n",
      "config - INFO - Log File: c:\\Users\\Rahul Gupta\\Documents\\RG\\GenAI\\0.self_explore\\logs\\custom_rag_2024_05_17_11_36_31.log\n",
      "config - INFO - Documents Directory: c:\\Users\\Rahul Gupta\\Documents\\RG\\GenAI\\0.self_explore\\documents\n",
      "config - INFO - Documents folder being read: c:\\Users\\Rahul Gupta\\Documents\\RG\\GenAI\\0.self_explore\\documents\\coe_demo\n"
     ]
    }
   ],
   "source": [
    "from config import *\n",
    "\n",
    "logger.info(f\"Documents Directory: {docs_dir}\")\n",
    "logger.info(f\"Documents folder being read: {docs_dir}{separator}{docs_folder_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# Capturing individual documents name from a particular directory\n",
    "# \n",
    "\n",
    "def get_docs_name():\n",
    "    logger.debug(f'#### ENTER get_docs_name() function ####')\n",
    "    actual_docs_dir = f\"{docs_dir}{separator}{docs_folder_name}{separator}\"\n",
    "    logger.debug(f'Reading documents from path:\\n{actual_docs_dir}')\n",
    "\n",
    "    docs_name = []\n",
    "\n",
    "    for filename in os.listdir(actual_docs_dir):\n",
    "        if filename.lower().endswith((\".pdf\", \".txt\")):\n",
    "            docs_name.append(filename)\n",
    "            \n",
    "    logger.info(f'Documents being processed:')\n",
    "    for i, doc in enumerate(docs_name):\n",
    "        logger.info(f'({i+1}) {doc}')\n",
    "    \n",
    "    logger.debug(f'#### EXIT get_docs_name() function ####')\n",
    "    return docs_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# Add extra metadata to each document\n",
    "# \n",
    "def add_metadata(doc):\n",
    "    logger.debug(f'#### ENTER add_metadata() function ####')\n",
    "\n",
    "    # Get the directory separator for the platform\n",
    "    # separator = os.path.sep\n",
    "    # print(f'Folder separator used w.r.t OS: {separator}')\n",
    "    start = doc.metadata[\"source\"].rfind(separator)\n",
    "    # print(start)\n",
    "    # end = doc.metadata[\"source\"].find('.pdf')\n",
    "    # print(end)\n",
    "    # print(f'Doc name: {doc.metadata[\"source\"][start+1:end]}')\n",
    "    doc.metadata[\"name\"] = doc.metadata[\"source\"][start+1:]\n",
    "    key = \"page\"\n",
    "    if key not in doc.metadata:\n",
    "        # print(f\"{key} does not exist in the document metadata\")\n",
    "        doc.metadata[key] = 0\n",
    "    # print(doc.metadata)\n",
    "\n",
    "    logger.debug(f'#### EXIT add_metadata() function ####')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# load all documents inside a particular directory\n",
    "#\n",
    "#\n",
    "def load_all_docs():\n",
    "    logger.debug(f'#### ENTER load_all_docs() function ####')\n",
    "\n",
    "    all_docs = []\n",
    "    # docs_dir = f\"./documents/{docs_folder_name}/\"\n",
    "    actual_docs_dir = f\"{docs_dir}{separator}{docs_folder_name}{separator}\"\n",
    "    \n",
    "    book_name = get_docs_name()\n",
    "\n",
    "    for filename in os.listdir(actual_docs_dir):\n",
    "        # Loading pdf docs\n",
    "        if filename.lower().endswith(\".pdf\"):\n",
    "            logger.info(f\"Loading document: {filename}...\")\n",
    "            loader = PyPDFLoader(f'{actual_docs_dir}{separator}{filename}')\n",
    "        # load txt files\n",
    "        elif filename.lower().endswith(\".txt\"):\n",
    "            logger.info(f\"Loading file: {filename}...\")\n",
    "            loader = TextLoader(f'{actual_docs_dir}{separator}{filename}')\n",
    "        else:\n",
    "            logger.warning(f'No loader defined for this file: {filename}')\n",
    "            continue\n",
    "            \n",
    "        \n",
    "        # loader split in pages\n",
    "        docs = loader.load()\n",
    "\n",
    "        # looping to add extra metadata to each page\n",
    "        logger.debug(\"Original documents loaded as-is\")\n",
    "        for i, doc in enumerate(docs):\n",
    "            add_metadata(doc)\n",
    "            if DEBUG:\n",
    "                logger.debug(f'Doc {i+1} Page Content: {doc.page_content}')\n",
    "                logger.debug(f'Doc {i+1} Metdata: {doc.metadata}')\n",
    "\n",
    "        all_docs.extend(docs)\n",
    "\n",
    "    logger.info(f\"\\nLoaded {len(all_docs)} docs...\\n\")\n",
    "    # print(f'##### All docs ####:\\n')\n",
    "    # [print(f'{doc}\\n') for doc in all_docs]\n",
    "\n",
    "    logger.debug(f'#### EXIT load_all_docs() function ####')\n",
    "    return all_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# do some post processing on text\n",
    "#\n",
    "def post_process(splits):\n",
    "    logger.debug(f'#### ENTER post_process() function ####')\n",
    "    for split in splits:\n",
    "        # replace newline with blank\n",
    "        split.page_content = split.page_content.replace(\"\\n\", \" \")\n",
    "        split.page_content = re.sub(\"[^a-zA-Z0-9 \\n\\.]\", \" \", split.page_content)\n",
    "        split.page_content = re.sub(r\"\\.{2,}\", \".\", split.page_content)\n",
    "        # remove duplicate blank\n",
    "        split.page_content = \" \".join(split.page_content.split())\n",
    "\n",
    "    logger.debug(f'#### EXIT post_process() function ####')\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Split pages in chunk\n",
    "#\n",
    "def split_in_chunks(all_docs):\n",
    "    logger.debug(f'#### ENTER split_in_chunks() function ####')\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        separators=[\"(?<=\\. )\", \"\\n\"],\n",
    "        chunk_size=CHUNK_SIZE, \n",
    "        chunk_overlap=CHUNK_OVERLAP, \n",
    "        length_function=len\n",
    "    )\n",
    "\n",
    "    chunks = text_splitter.split_documents(all_docs)\n",
    "    logger.info(f\"Splitted the document in {len(chunks)} chunks...\")\n",
    "    \n",
    "    # some post processing on text\n",
    "    chunks = post_process(chunks)\n",
    "    if DEBUG:\n",
    "        logger.debug('=============CHUNKED & POST PROCESSED DOCUMENTS=============')\n",
    "        for i, item in enumerate(chunks):\n",
    "            logger.debug(f'Chunk ({i+1}):\\n {item}')\n",
    "\n",
    "    non_empty_chunks = []\n",
    "    for i, item in enumerate(chunks):\n",
    "        if dict(item)['page_content'] != '':\n",
    "            non_empty_chunks.append(item)\n",
    "        \n",
    "    logger.info(f\"Number of non-empty chunks: {len(non_empty_chunks)}\")\n",
    "\n",
    "    logger.debug(f'#### EXIT split_in_chunks() function ####')\n",
    "    return non_empty_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config - INFO - Documents being processed:\n",
      "config - INFO - (1) data-science-lifecycle-ebook.pdf\n",
      "config - INFO - (2) oracle-autonomous-database-technical-overview.pdf\n",
      "config - INFO - Loading document: data-science-lifecycle-ebook.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config - INFO - Loading document: oracle-autonomous-database-technical-overview.pdf...\n",
      "config - INFO - \n",
      "Loaded 32 docs...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Load a list of pdf documents\n",
    "# all_docs = load_all_docs()\n",
    "# all_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config - INFO - Splitted the document in 145 chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config - INFO - Number of non-empty chunks: 145\n"
     ]
    }
   ],
   "source": [
    "# 2. Split pages in chunks\n",
    "# document_chunks = split_in_chunks(all_docs)\n",
    "# document_chunks\n",
    "# doc_list, metadata_list = docs_and_metadata(document_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config - INFO - #### ENTER release_log_file() function ####\n",
      "config - INFO - Releasing log file...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log file released successfully.\n"
     ]
    }
   ],
   "source": [
    "# release_log_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condarag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
